{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "import concurrent.futures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>genre</th>\n",
       "      <th>numsongs</th>\n",
       "      <th>lyrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Abrasive Wheels</td>\n",
       "      <td>punk</td>\n",
       "      <td>10</td>\n",
       "      <td>Got my marching orders in the morning post Whe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Adverts</td>\n",
       "      <td>punk</td>\n",
       "      <td>10</td>\n",
       "      <td>Life's short, don't make a mess of it To the e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Alternative TV</td>\n",
       "      <td>punk</td>\n",
       "      <td>10</td>\n",
       "      <td>Action, time and vision Action, time and visio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Anti-Pasti</td>\n",
       "      <td>punk</td>\n",
       "      <td>10</td>\n",
       "      <td>See how they run With their backs Against the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Au Pairs</td>\n",
       "      <td>punk</td>\n",
       "      <td>10</td>\n",
       "      <td>Spending time nowadays Nowadays it’s nice It’s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1925</th>\n",
       "      <td>The Four Horsemen</td>\n",
       "      <td>hard rock</td>\n",
       "      <td>10</td>\n",
       "      <td>I'm keeping a heater I'm doing the best I can ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1936</th>\n",
       "      <td>Blackfoot</td>\n",
       "      <td>country</td>\n",
       "      <td>10</td>\n",
       "      <td>You took his land and you ate his corn And on ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1938</th>\n",
       "      <td>Atomic Opera</td>\n",
       "      <td>hard rock</td>\n",
       "      <td>10</td>\n",
       "      <td>I want a Virgin Mary nightlamp Bible hero lunc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1950</th>\n",
       "      <td>Asterix</td>\n",
       "      <td>hard rock</td>\n",
       "      <td>10</td>\n",
       "      <td>⒯⋆̶⋆'⋆̶⋆⒧⋆̶⋆⒜⋆̶⋆⒣⋆̶⋆ ⒣⋆̶⋆⒜⋆̶⋆⒝⋆̶⋆⒤⋆̶⋆⒮⋆̶⋆ ⒦⋆̶⋆...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1953</th>\n",
       "      <td>Dokken</td>\n",
       "      <td>hard rock</td>\n",
       "      <td>10</td>\n",
       "      <td>Sit there thinking In your room You feel the p...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 artist      genre  numsongs   \n",
       "1       Abrasive Wheels       punk        10  \\\n",
       "4           The Adverts       punk        10   \n",
       "8        Alternative TV       punk        10   \n",
       "13           Anti-Pasti       punk        10   \n",
       "14             Au Pairs       punk        10   \n",
       "...                 ...        ...       ...   \n",
       "1925  The Four Horsemen  hard rock        10   \n",
       "1936          Blackfoot    country        10   \n",
       "1938       Atomic Opera  hard rock        10   \n",
       "1950            Asterix  hard rock        10   \n",
       "1953             Dokken  hard rock        10   \n",
       "\n",
       "                                                 lyrics  \n",
       "1     Got my marching orders in the morning post Whe...  \n",
       "4     Life's short, don't make a mess of it To the e...  \n",
       "8     Action, time and vision Action, time and visio...  \n",
       "13    See how they run With their backs Against the ...  \n",
       "14    Spending time nowadays Nowadays it’s nice It’s...  \n",
       "...                                                 ...  \n",
       "1925  I'm keeping a heater I'm doing the best I can ...  \n",
       "1936  You took his land and you ate his corn And on ...  \n",
       "1938  I want a Virgin Mary nightlamp Bible hero lunc...  \n",
       "1950  ⒯⋆̶⋆'⋆̶⋆⒧⋆̶⋆⒜⋆̶⋆⒣⋆̶⋆ ⒣⋆̶⋆⒜⋆̶⋆⒝⋆̶⋆⒤⋆̶⋆⒮⋆̶⋆ ⒦⋆̶⋆...  \n",
       "1953  Sit there thinking In your room You feel the p...  \n",
       "\n",
       "[500 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get lyrics data\n",
    "data = pd.read_csv(\"final_data.csv\")\n",
    "\n",
    "#trim data, it was taking too long to do all of them\n",
    "rows_to_drop = data.sample(n=1454, random_state=42).index\n",
    "\n",
    "data = data.drop(rows_to_drop)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0-11): 12 x BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load the tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "#load bert model and put in eval mode\n",
    "model = BertModel.from_pretrained('bert-base-uncased', output_hidden_states=True)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_embeddings(start_index, end_index, df):\n",
    "\n",
    "        #this will be a dictionary mapping an artist to that artist's respective embedding and genre, (embedding,genre), the contents of this dict will later be saved to a json file\n",
    "    artist_embedding_dict = dict()\n",
    "\n",
    "\n",
    "\n",
    "    for index, row in df.iloc[start_index:end_index].iterrows():\n",
    "\n",
    "        #get info from row\n",
    "        artist = row[\"artist\"]\n",
    "        genre = row[\"genre\"]\n",
    "        lyrics = row[\"lyrics\"]\n",
    "\n",
    "        #convert lyrics to list of tokens\n",
    "        list_of_tokens = tokenizer.tokenize(lyrics)\n",
    "\n",
    "        #split the entire list of tokens into lists of 510 tokens, as that will be the max number of tokens we can make an\n",
    "        #embedding for after adding the special tokens\n",
    "\n",
    "        lyrics_split_list = []\n",
    "\n",
    "        temp_list = []\n",
    "        for i,token in enumerate(list_of_tokens):\n",
    "            \n",
    "            if i % 510 == 0 and i != 0:\n",
    "                lyrics_split_list.append(temp_list)\n",
    "                temp_list = []\n",
    "            \n",
    "            temp_list.append(token)\n",
    "\n",
    "        lyrics_split_list.append(temp_list)\n",
    "\n",
    "\n",
    "        #for each list of tokens, add special tokens to front and back\n",
    "        # and then map tokens to their vocabulary indices for each list of tokens\n",
    "        # and make segment ids, this will just be lists of all 1's \n",
    "        indexed_tokens_list = []\n",
    "        segment_ids = []\n",
    "\n",
    "        for l in lyrics_split_list:\n",
    "            l.insert(0,\"[CLS]\")\n",
    "            l.append(\"[SEP]\")\n",
    "            segment_ids.append([1] * len(l))\n",
    "            indexed_tokens_list.append(tokenizer.convert_tokens_to_ids(l))\n",
    "        \n",
    "        #convert to tensors\n",
    "        tokens_tensor_list = []\n",
    "        segment_tensor_list = []\n",
    "\n",
    "        for i, l in enumerate(indexed_tokens_list):\n",
    "            tokens_tensor_list.append(torch.tensor([l]))\n",
    "            segment_tensor_list.append(torch.tensor([segment_ids[i]]))\n",
    "\n",
    "        #run tensors through bert and get the hidden states\n",
    "        with torch.no_grad():\n",
    "\n",
    "            hidden_state_list = []\n",
    "\n",
    "            for i, l in enumerate(tokens_tensor_list):\n",
    "                output = model(l, segment_tensor_list[i])\n",
    "                hidden_state_list.append(output[2])\n",
    "        \n",
    "        embeddings = []\n",
    "\n",
    "        for state in hidden_state_list:\n",
    "            token_vectors = state[-2][0]\n",
    "            embeddings.append(torch.mean(token_vectors,dim=0))\n",
    "\n",
    "        artist_embedding = torch.mean(torch.stack(embeddings), dim=0)\n",
    "\n",
    "        #make it a python list so it is json serializable\n",
    "        artist_embedding_dict[artist] = artist_embedding.tolist()\n",
    "\n",
    "    return artist_embedding_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def process_dataframe(df, num_threads):\n",
    "    results = []\n",
    "    chunk_size = len(df) // num_threads\n",
    "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "        futures = []\n",
    "        start_index = 0\n",
    "        for i in range(num_threads):\n",
    "            end_index = start_index + chunk_size if i < num_threads - 1 else None\n",
    "            future = executor.submit(create_embeddings, start_index, end_index, df)\n",
    "            futures.append(future)\n",
    "            start_index = end_index\n",
    "        for future in concurrent.futures.as_completed(futures):\n",
    "            result = future.result()\n",
    "            results.append(result)\n",
    "    return results\n",
    "\n",
    "\n",
    "\n",
    "# Set the number of threads\n",
    "num_threads = 4\n",
    "\n",
    "# Process the dataframe using 4 threads\n",
    "processed_data = process_dataframe(data, num_threads)\n",
    "\n",
    "total_dict = {}\n",
    "\n",
    "for d in processed_data:\n",
    "    total_dict.update(d)\n",
    "\n",
    "with open(\"500_artist_embeddings.json\", \"w+\") as f:\n",
    "    json.dump(total_dict,f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Batch 0\n",
      "Starting Batch 1\n",
      "Starting Batch 2\n",
      "Starting Batch 3\n",
      "Starting Batch 4\n",
      "Starting Batch 5\n",
      "Starting Batch 6\n",
      "Starting Batch 7\n",
      "Starting Batch 8\n",
      "Starting Batch 9\n",
      "Starting Batch 10\n",
      "Starting Batch 11\n",
      "Starting Batch 12\n",
      "Starting Batch 13\n",
      "Starting Batch 14\n",
      "Starting Batch 15\n",
      "Starting Batch 16\n",
      "Starting Batch 17\n",
      "Starting Batch 18\n",
      "Starting Batch 19\n",
      "Starting Batch 20\n",
      "Starting Batch 21\n",
      "Starting Batch 22\n",
      "Starting Batch 23\n",
      "Starting Batch 24\n"
     ]
    }
   ],
   "source": [
    "#larger trial\n",
    "\n",
    "data = pd.read_csv(\"final_data.csv\")\n",
    "\n",
    "large_total_dict = {}\n",
    "\n",
    "batch_size = 20\n",
    "\n",
    "# Create a generator function to yield rows in batches\n",
    "def batch_iterator(dataframe, batch_size):\n",
    "    num_rows = len(dataframe)\n",
    "    for i in range(0, num_rows, batch_size):\n",
    "        yield dataframe.iloc[i : i + batch_size]\n",
    "\n",
    "# Iterate over rows in batches\n",
    "for count,batch_df in enumerate(batch_iterator(data, batch_size)):\n",
    "    print(f\"Starting Batch {count}\")\n",
    "    temp_results = process_dataframe(batch_df, 4)\n",
    "\n",
    "    for r in temp_results:\n",
    "        large_total_dict.update(r)\n",
    "\n",
    "with open(\"2000_artist_embeddings.json\", \"w+\") as f:\n",
    "    json.dump(total_dict,f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
